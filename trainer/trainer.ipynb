{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_to_move(code):\n",
    "    if code==0:\n",
    "        return \"left\"\n",
    "    elif code==1:\n",
    "        return \"up\"\n",
    "    elif code==2:\n",
    "        return \"right\"\n",
    "    elif code==3:\n",
    "        return \"down\"\n",
    "    else:\n",
    "        return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from numpy import genfromtxt\n",
    "\n",
    "# Read mazes from .csv\n",
    "def read_mazes(directory='./mazes/', num_mazes=10):\n",
    "    mazes = []\n",
    "    # Iterate over all csv files in the specified directory\n",
    "    cur_count = 0\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            print(filepath)\n",
    "\n",
    "            # Read csv into np array, then convert to MazeMap\n",
    "            cur_maze = genfromtxt(filepath, delimiter=',')\n",
    "            mazes.append(MazeMap(cur_maze))\n",
    "        cur_count += 1\n",
    "        if cur_count == num_mazes:\n",
    "            break\n",
    "            \n",
    "    return mazes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "class MazeSet:\n",
    "    def __init__(self, maze_list):\n",
    "        self.maze_list = maze_list\n",
    "        self.len = len(maze_list)\n",
    "        self.index = 0\n",
    "        self.current = maze_list[0]\n",
    "        self.map_history = [[] for i in range(self.len)]\n",
    "    \n",
    "    # Cycle to next maze in the training set\n",
    "    def next(self):\n",
    "        # Circular array\n",
    "        self.index += 1\n",
    "        if self.index == self.len:\n",
    "            self.index = 0\n",
    "        \n",
    "        # Change current maze\n",
    "        self.current = maze_list[self.index]\n",
    "        \n",
    "        # Return new maze\n",
    "        return copy.deepcopy(self.current)\n",
    "    \n",
    "    # Return current maze\n",
    "    def get_maze(self):\n",
    "        return copy.deepcopy(self.current)\n",
    "    \n",
    "    # Add another maze to the training set\n",
    "    def add(self, new_maze):\n",
    "        self.maze_list.append(new_maze)\n",
    "        self.len += 1\n",
    "        self.map_history.append([])\n",
    "    \n",
    "    def record_history(self, num_episodes):\n",
    "        self.map_history[self.index].append(num_episodes)\n",
    "\n",
    "    def get_map_hist(self):\n",
    "        return self.map_history[self.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./mazes/m1.csv\n",
      "./mazes/m10.csv\n",
      "./mazes/m2.csv\n",
      "./mazes/m3.csv\n",
      "./mazes/m4.csv\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'build_model_reduced' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-d280832ba9ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[0mtraining_mazes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMazeSet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaze_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[1;31m#model = build_model(maze_test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_model_reduced\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaze_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m \u001b[0mstart_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_mazes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmaze_map\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_state_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'build_model_reduced' is not defined"
     ]
    }
   ],
   "source": [
    "from utils import build_model, build_model_reduced\n",
    "from replay import Episode, ReplyBuffer\n",
    "import numpy as np\n",
    "from mazemap import Action, MazeMap, Mode\n",
    "import tensorflowjs as tfjs\n",
    "\n",
    "maze_test2 = np.array([\n",
    "    [ 0., 1., 0., 0., 0., 0., 0., 0. ],\n",
    "    [ 0., 0., 0., 1., 1., 0., 1., 0. ],\n",
    "    [ 1., 1., 1., 0., 0., 0., 1., 0. ],\n",
    "    [ 0., 0., 0., 0., 1., 1., 0., 0. ],\n",
    "    [ 0., 1., 1., 1., 0., 0., 0., 1. ],\n",
    "    [ 0., 1., 0., 0., 0., 0., 0., 1. ],\n",
    "    [ 0., 0., 0., 1., 0., 0., 0., 1. ],\n",
    "    [ 0., 0., 0., 1., 0., 0., 0., 0. ],\n",
    "])\n",
    "\n",
    "maze_test = np.zeros((8,8))\n",
    "\n",
    "\n",
    "def start_train(model,\n",
    "                maze_set: MazeSet, \n",
    "                num_epoch = 15000, \n",
    "                max_buffer = 1000, \n",
    "                sample_size = 50,\n",
    "                gamma = 0.9,\n",
    "                history_size = None,\n",
    "                print_steps = False,\n",
    "                load_path = None,\n",
    "                save_path = None):\n",
    "    global epsilon\n",
    "    global AT_rate\n",
    "\n",
    "    if save_path == None:\n",
    "        save_path = 'maze_model'\n",
    "\n",
    "    if load_path != None:\n",
    "        print(f'Load weight from {load_path}')\n",
    "        model.load_weights(load_path)\n",
    "\n",
    "    maze = maze_set.get_maze()\n",
    "    maze_map = maze\n",
    "\n",
    "    replay_buf: ReplyBuffer = ReplyBuffer(model, maze_map.get_state_size(), max_buffer, gamma)\n",
    "\n",
    "    history = []\n",
    "    loss = 0.0\n",
    "    if history_size:\n",
    "        hsize = history_size\n",
    "    else:\n",
    "        hsize = maze.get_state_size() // 2\n",
    "    \n",
    "    print(\"Initialization complete, begin training\")\n",
    "    # Run training epoch\n",
    "    for epoch in range(num_epoch):\n",
    "        loss = 0.\n",
    "        is_over = False\n",
    "\n",
    "        curr_state = maze.observe()\n",
    "        print(curr_state.shape)\n",
    "        num_episode = 0\n",
    "        if print_steps:\n",
    "            mode = 'init'\n",
    "        \n",
    "        while not is_over:\n",
    "            valid_actions = maze.get_valid_actions()\n",
    "            #print(\"valid_actions:\", valid_actions)\n",
    "            if len(valid_actions) == 0:\n",
    "                break\n",
    "\n",
    "            # Explore\n",
    "            explore = True\n",
    "            accelerated_training = False\n",
    "            action = np.random.choice(valid_actions)\n",
    "            if np.random.rand() > epsilon:\n",
    "                # Exploit\n",
    "                explore = False\n",
    "                action = np.argmax(replay_buf.predict(curr_state))\n",
    "            else:\n",
    "                # Accelerated training\n",
    "                if np.random.rand() < AT_rate:\n",
    "                    explore = False\n",
    "                    accelerated_training = True\n",
    "                    path,distance = maze.path_to_end()\n",
    "                    opt_row, opt_col = path[0]\n",
    "                    cur_row, cur_col = maze.curr_loc\n",
    "                    if opt_row > cur_row:\n",
    "                        action = Action.DOWN\n",
    "                    elif opt_row < cur_row:\n",
    "                        action = Action.UP\n",
    "                    elif opt_col > cur_col:\n",
    "                        action = Action.RIGHT\n",
    "                    elif opt_col < cur_col:\n",
    "                        action = Action.LEFT\n",
    "                    else:\n",
    "                        print(\"AT ERROR\")\n",
    "            action = Action(action)\n",
    "            if print_steps:\n",
    "                print(\"Episode num:\",num_episode)\n",
    "                print(\"Old loc:\",maze.curr_loc)\n",
    "            prev_state = curr_state\n",
    "            curr_state, reward, mode = maze.act(action)\n",
    "            mode = Mode(mode)\n",
    "            if print_steps:\n",
    "                print(mode)\n",
    "                print(\"New loc:\",maze.curr_loc)\n",
    "                print(\"Chosen action:\",code_to_move(action),\"\\treward:\",reward)\n",
    "                if explore:\n",
    "                    print(\"Randomly picked with explore\")\n",
    "                if accelerated_training:\n",
    "                    print(\"Optimal pick with accelerated training\")\n",
    "                maze.print_maze(mouse_char=':>')\n",
    "                print()\n",
    "            if mode == Mode.END:\n",
    "                history.append(1)\n",
    "                is_over = True\n",
    "            elif mode == Mode.TERMINATED:\n",
    "                history.append(0)\n",
    "                is_over = True\n",
    "            else:\n",
    "                is_over = False\n",
    "\n",
    "            episode = Episode(prev_state, curr_state, action, reward, mode)\n",
    "            replay_buf.log(episode)\n",
    "            num_episode += 1\n",
    "\n",
    "            inputs, outputs = replay_buf.sampling(sample_size)\n",
    "            train_history = model.fit(inputs, outputs, epochs=8, batch_size=16, verbose=0)\n",
    "            loss = train_history.history['loss'][-1]\n",
    "        \n",
    "        win_rate = 0.0 if len(history) < hsize else np.sum(np.array(history[-hsize:])) / hsize\n",
    "\n",
    "        print(f'Epoch {epoch}/{num_epoch} | Loss: {loss:.2f} | Episodes: {num_episode} | Win Count: {np.sum(np.array(history))} | Win Rate: {win_rate}')\n",
    "    \n",
    "        # Record number of episodes for the model for this epoch on the current map\n",
    "        maze_set.record_history((num_episode, int(is_over)))\n",
    "    \n",
    "        \n",
    "        # Reset maze after epoch ends\n",
    "        maze = maze_set.get_maze()\n",
    "        if loss > 5:\n",
    "            epsilon = .5\n",
    "            at_rate = .95\n",
    "        elif loss > 1.5:\n",
    "            epsilon = .25\n",
    "            at_rate = .8\n",
    "        elif loss < 1.5:\n",
    "            epsilon = .2\n",
    "            at_rate = .5\n",
    "            if loss < 1:\n",
    "                epsilon = .15\n",
    "                at_rate = .25\n",
    "                if loss < .5:\n",
    "                    epsilon = .1\n",
    "                    at_rate = .1\n",
    "            \n",
    "        # Prevent the model getting stuck in a local minimum where it loops\n",
    "        if num_episode > 60:\n",
    "            epsilon = .2\n",
    "            at_rate = .3\n",
    "            \n",
    "        if win_rate > 0.9:\n",
    "            epsilon = 0.05\n",
    "            at_rate = 0\n",
    "        \n",
    "        if win_rate == 1.0:\n",
    "            print('Reach 100% win rate')\n",
    "            # Print the model's history on the map\n",
    "            print(maze_set.get_map_hist())\n",
    "            # Change to next maze in training set\n",
    "            maze = maze_set.next()\n",
    "            history = []\n",
    "            \n",
    "        if epoch % 15 == 0:\n",
    "            h5file = save_path + \".h5\"\n",
    "            model.save_weights(h5file, overwrite=True)\n",
    "            tfjs.converters.save_keras_model(model, './')\n",
    "            \n",
    "            print(f'Saved model in {save_path}')\n",
    "            \n",
    "        if print_steps:\n",
    "            maze.print_maze(mouse_char=':>')\n",
    "\n",
    "    h5file = save_path + \".h5\"\n",
    "    model.save_weights(h5file, overwrite=True)        \n",
    "    tfjs.converters.save_keras_model(model, './')\n",
    "    print(f'Saved model in {save_path}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# This hyperparamter is used to control the ratio of exploration and exploitation\n",
    "epsilon = 0.1\n",
    "# This hyperparameter is used to control the ratio of random vs optimized exploration\n",
    "AT_rate = .5\n",
    "\n",
    "maze_map = MazeMap(maze_test)\n",
    "#maze_list = [maze_map, MazeMap(maze_test2)]\n",
    "maze_list = read_mazes(num_mazes=5)\n",
    "\n",
    "training_mazes = MazeSet(maze_list)\n",
    "model = build_model(maze_test)\n",
    "#model = build_model_reduced(maze_test)\n",
    "start_train(model, training_mazes, 300, 8 * maze_map.get_state_size(), history_size=5, print_steps=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "implement accelerated training:\n",
    "some % of the time, instead of explore being a random choice, it is the optimum choice\n",
    "  \n",
    "at higher loss values, this occurs more often, and doesn't occur at all for lower loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import build_model\n",
    "from replay import Episode, ReplyBuffer\n",
    "import numpy as np\n",
    "from mazemap import Action, MazeMap, Mode\n",
    "import tensorflowjs as tfjs\n",
    "\n",
    "maze_test2 = np.array([\n",
    "    [ 0., 1., 0., 0., 0., 0., 0., 0. ],\n",
    "    [ 0., 0., 0., 1., 1., 0., 1., 0. ],\n",
    "    [ 1., 1., 1., 0., 0., 0., 1., 0. ],\n",
    "    [ 0., 0., 0., 0., 1., 1., 0., 0. ],\n",
    "    [ 0., 1., 1., 1., 0., 0., 0., 1. ],\n",
    "    [ 0., 1., 0., 0., 0., 0., 0., 1. ],\n",
    "    [ 0., 0., 0., 1., 0., 0., 0., 1. ],\n",
    "    [ 0., 0., 0., 1., 0., 0., 0., 0. ],\n",
    "])\n",
    "\n",
    "maze_test = np.zeros((8,8))\n",
    "\n",
    "maze_map = MazeMap(maze_test)\n",
    "path,distance = maze_map.path_to_end()\n",
    "print(distance, path)\n",
    "\n",
    "maze_map = MazeMap(maze_test2)\n",
    "path,distance = maze_map.path_to_end()\n",
    "print(distance, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
